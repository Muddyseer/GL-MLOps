name: Azure ML Pipeline Trigger
on: [push, workflow_dispatch]

jobs:
  run_pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup Python and Azure ML
        run: |
          python -m pip install --upgrade pip
          pip install azure-ai-ml
          az extension add -n ml --yes

      - name: Run Complete Pipeline
        run: |
          python - <<EOF
          from azure.ai.ml import MLClient, Input, command, sweep
          from azure.ai.ml.dsl import pipeline
          from azure.identity import DefaultAzureCredential

          # Connect to workspace
          ml_client = MLClient(
              DefaultAzureCredential(),
              subscription_id="${{ secrets.AZURE_SUBSCRIPTION_ID }}",
              resource_group_name="${{ secrets.AZURE_RESOURCE_GROUP }}",
              workspace_name="${{ secrets.AZURE_WORKSPACE }}",
          )

          # Define components
          @command(
              name="prep_data",
              display_name="Data Preparation",
              environment="AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest"
          )
          def prep_data(raw_data: Input(type="uri_file"), test_train_ratio: float = 0.8):
              return {
                  "train_data": Output(type="uri_folder"),
                  "test_data": Output(type="uri_folder")
              }

          @command(
              name="train_model",
              display_name="Train Model",
              environment="AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest"
          )
          def train_model(
              train_data: Input(type="uri_folder"),
              test_data: Input(type="uri_folder"),
              n_estimators: int = 50,
              max_depth: int = None
          ):
              return {
                  "model_output": Output(type="mlflow_model")
              }

          # Build pipeline
          @pipeline()
          def full_pipeline(raw_data):
              # Data prep
              prep = prep_data(
                  raw_data=raw_data,
                  test_train_ratio=0.8
              )

              # Training with sweep
              train = train_model(
                  train_data=prep.outputs.train_data,
                  test_data=prep.outputs.test_data
              )
              sweep_job = train.sweep(
                  compute="cpu-cluster",
                  sampling_algorithm="random",
                  primary_metric="MSE",
                  goal="Minimize",
                  search_space={
                      "n_estimators": sweep.Choice(values=[10, 20, 30, 50]),
                      "max_depth": sweep.Choice(values=[3, 5, 10, None])
                  }
              )
              sweep_job.set_limits(
                  max_total_trials=20,
                  max_concurrent_trials=10,
                  timeout=7200
              )

              return {
                  "best_model": sweep_job.outputs.model_output
              }

          # Submit pipeline
          pipeline_job = full_pipeline(
              raw_data=Input(
                  path="${{ secrets.AZURE_DATA_PATH }}",
                  type="uri_file"
              )
          )
          ml_client.jobs.create_or_update(pipeline_job)
          print(f"Pipeline submitted with ID: {pipeline_job.name}")
          EOF
